{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohlDhP9yB4KZ"
   },
   "source": [
    "# Foundations of Machine Learning Models\n",
    "\n",
    "## Assignment: Custom Transformer and Transformation Pipeline\n",
    "\n",
    "#### Name: Richard Lee\n",
    "\n",
    "### Details\n",
    "Your task in this assignment is to create a custom transformation pipeline that takes in raw data and returns fully prepared, clean data that is ready for model training.  However, we will not actually train any models in this assignment.  This pipeline will employ an imputer class, a user-defined transformer class, and a data-normalization class.\n",
    "\n",
    "Please note that the order of features in the final feature matrix must be correct.  See the below figure that illustrates the input and output of the transformation pipeline.  The positions of features $x_1$ and $x_2$ do not change - they remain in the first and second columns, respectively, both before and after the transformation pipeline.  In the transformed dataset, the $x_5$ feature is next, and is followed by the newly computed feature $x_6$.  Finally, the last two columns are the remaining one-hot vectors obtained from encoding the categorical feature $x_3$.\n",
    "\n",
    "<img src=\"DataTransformation.png \" width =\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paEI44LpB4Kg"
   },
   "source": [
    "# Import Data\n",
    "\n",
    "- Make sure that your notebook and data file are located in the same folder since this is what CodeGrade will be expecting.  \n",
    "- Import the data from the file called `CustomTransformerData.csv` and call this DataFrame `custom_transform`.  \n",
    "- Output the `custom_transform` DataFrame to see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1624045785118,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "iviPNPMhB4Kh",
    "outputId": "67710931-03a9-494d-c85f-e7095ab12143"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.354153</td>\n",
       "      <td>COLD</td>\n",
       "      <td>593</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.314048</td>\n",
       "      <td>WARM</td>\n",
       "      <td>340</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.021604</td>\n",
       "      <td>COLD</td>\n",
       "      <td>551</td>\n",
       "      <td>4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLD</td>\n",
       "      <td>2368</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.847601</td>\n",
       "      <td>WARM</td>\n",
       "      <td>2636</td>\n",
       "      <td>10.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1        x2    x3    x4         x5\n",
       "0  1.5  2.354153  COLD   593   0.750000\n",
       "1  2.5  3.314048  WARM   340   2.083333\n",
       "2  3.5  4.021604  COLD   551   4.083333\n",
       "3  4.5       NaN  COLD  2368   6.750000\n",
       "4  5.5  5.847601  WARM  2636  10.083333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "custom_transform = pd.read_csv('CustomTransformerData.csv')\n",
    "\n",
    "custom_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nopVKUnbB4Kt"
   },
   "source": [
    "# Create Numeric and Categorical DataFrames\n",
    "\n",
    "- Create two new DataFrames: \n",
    "  - Create one DataFrame called `data_num` that holds the numeric features from the `custom_transform` DataFrame.  \n",
    "  - Create another DataFrame called `data_cat` that holds the categorical feature from `custom_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624045786487,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "qj5GZ5YiB4Ku"
   },
   "outputs": [],
   "source": [
    "data_num = custom_transform.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    x1        x2    x4         x5\n",
       " 0  1.5  2.354153   593   0.750000\n",
       " 1  2.5  3.314048   340   2.083333\n",
       " 2  3.5  4.021604   551   4.083333\n",
       " 3  4.5       NaN  2368   6.750000\n",
       " 4  5.5  5.847601  2636  10.083333,\n",
       "      x3\n",
       " 0  COLD\n",
       " 1  WARM\n",
       " 2  COLD\n",
       " 3  COLD\n",
       " 4  WARM)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = custom_transform.select_dtypes(include=['object'])\n",
    "data_num.head(), data_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASUFXY7BB4Km"
   },
   "source": [
    "# Create Custom Transformer\n",
    "\n",
    "Create a custom transformer, just as we did in the lecture video entitled \"Custom Transformers\", that performs two computations: \n",
    "\n",
    "1. Adds an attribute to the end of the numerical data (i.e. new last column) that is equal to $\\frac{x_1^3}{x_5}$ for each observation.  In other words, for each instance, you will cube the $x_1$ column and then divide by the $x_5$ column.\n",
    "\n",
    "2. Drops the entire $x_4$ feature column if the passed function argument `drop_x4` is `True` and doesn't drop the column if `drop_x4` is `False`. (See further instructions below.)\n",
    "\n",
    "You must name your custom transformer class `AssignmentTransformer`. Your class should include an input parameter called `drop_x4` with a default value of `True` that deletes the $x_4$ feature column when its value is `True`, but preserves the $x_4$ feature column when you pass a value of `False`.\n",
    "\n",
    "This transformer will be used in a pipeline. In that pipeline, an imputer will be run *before* this transformer. Keep in mind that the imputer will output an array, so **this transformer must be written to accept an array.**  This is very important and a cause of many errors that students encounter.  In other words, think about using NumPy in your transformer instead of Pandas.\n",
    "\n",
    "Additionally, this transformer will ONLY be given the numerical features of the data. The categorical feature will be handled elsewhere in the full pipeline. This means that your code for this transformer **must reflect the absence of the categorical $x_3$ column** when indexing data structures.  Again this is very important and a cause of the second most number of errors that students encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1624045786162,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "l5UgwTFtB4Kp"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "X1_INDEX = 0\n",
    "X5_INDEX = 3\n",
    "X4_INDEX = 2\n",
    "\n",
    "class AssignmentTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_x4=True):\n",
    "        self.drop_x4 = drop_x4\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        x6 = X[:, X1_INDEX]**3 / X[:, X5_INDEX]\n",
    "        X = np.c_[X, x6]\n",
    "\n",
    "        if self.drop_x4:\n",
    "            X = np.delete(X, X4_INDEX, 1)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzTuITvAB4Kr"
   },
   "source": [
    "# Create Transformation Pipeline for Numerical Features\n",
    "\n",
    "Create a custom transformation pipeline for only the numeric data called `num_pipeline` that:\n",
    "\n",
    "1. Applies the `SimpleImputer` class to the data, where the strategy is set to `mean`.  The name of this step should be \"imputer\".\n",
    "\n",
    "2. Applies the custom `AssignmentTransformer` class to the data.  Make sure that your custom transformer uses the default argument where you drop the $x_4$ column.  The name of this step should be \"custom_trans\".\n",
    "\n",
    "3. Applies the `StandardScaler` class to the data.  The name of this step should be \"std_scaler\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1624045786486,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "co6dm-JAB4Ks"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "    ('custom_trans', AssignmentTransformer()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLDPD7faB4Kv"
   },
   "source": [
    "# Quick Testing\n",
    "\n",
    "The full pipeline will be implemented with a `ColumnTransformer` class.  However, to be sure that our numeric pipeline is working properly, lets invoke the `fit_transform()` method of the `num_pipeline` object passing it your `data_num` DataFrame.  Save this output data into a variable called `data_num_trans`.\n",
    "\n",
    "### Run Pipeline and Create Transformed Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1624045786493,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "PJknn8GUB4Kw",
    "outputId": "29b16d57-08df-421d-b21a-0c061be1ea20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num_trans = num_pipeline.fit_transform(data_num)\n",
    "\n",
    "data_num_trans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18MuMZi_B4Kx"
   },
   "source": [
    "### One-Hot Encode Categorical Features\n",
    "\n",
    "Similarly, you will employ a `OneHotEncoder` class in the `ColumnTransformer` below to construct the final full pipeline.  However, let's instantiate an object of the `OneHotEncoder` class to use in the `ColumnTransformer`.\n",
    "\n",
    "1. Call this object `cat_encoder` that has the `drop` parameter set to `first`.  \n",
    "2. Also, include `sparse=False` when instantiating the object to make the auto grading work correctly.  \n",
    "3. Next, call the `fit_transform()` method and pass it your categorical data (`data_cat`).  \n",
    "4. Save this output data into a variable called `data_cat_OHE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "data_cat_OHE = cat_encoder.fit_transform(data_cat)\n",
    "\n",
    "data_cat_OHE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuUbjOPiB4K0"
   },
   "source": [
    "# Put it All Together with a Column Transformer\n",
    "\n",
    "Now, we are finally ready to construct the full transformation pipeline called `full_pipeline` that will transform our raw data into clean, ready-to-train data.  \n",
    "1. Construct this `ColumnTransformer` below.  Note that you will use:\n",
    "  - the `num_pipeline` in the full_pipeline with your numeric data\n",
    "  - the `cat_encoder` object in the full_pipeline with your categorical data\n",
    "2. Call the `fit_transform()` method on the original `custom_transform` data to obtain the final, clean data.  \n",
    "3. Save this output data into a variable called `data_trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1624045797883,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "7m2SuGOpB4K2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426,  0.        ,\n",
       "         1.        ],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809,  1.        ,\n",
       "         0.        ],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501,  0.        ,\n",
       "         1.        ],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348,  1.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, list(data_num.columns)),\n",
    "    (\"cat\", cat_encoder, list(data_cat.columns))\n",
    "])\n",
    "\n",
    "data_trans = full_pipeline.fit_transform(custom_transform)\n",
    "\n",
    "data_trans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcJ5AjtB4K3"
   },
   "source": [
    "# Prepare for Grading\n",
    "\n",
    "Prepare your `data_trans` NumPy array for grading by running the code below.  We are using the NumPy [around()](https://numpy.org/doc/stable/reference/generated/numpy.around.html) function to round all the values to 2 decimal places and this will return a NumPy array.\n",
    "\n",
    "Please double check that the final order of the features in this `data_trans` array matches what was given to you at the top of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1624045786716,
     "user": {
      "displayName": "Ben Pickard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPExDuYgUieHlogH8E532au3146lVrJ6Ixni9u=s64",
      "userId": "12452112282107072949"
     },
     "user_tz": 240
    },
    "id": "RME1nK-TB4K5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.64, -1.73, -1.2 , -1.59,  0.  ,  0.  ],\n",
       "       [-1.45, -1.53, -1.16, -1.4 ,  0.  ,  1.  ],\n",
       "       [-1.25, -1.38, -1.1 , -1.21,  0.  ,  0.  ],\n",
       "       [-1.06,  0.  , -1.03, -1.02,  0.  ,  0.  ],\n",
       "       [-0.87, -0.99, -0.93, -0.83,  0.  ,  1.  ],\n",
       "       [-0.67, -0.7 , -0.82, -0.64,  0.  ,  1.  ],\n",
       "       [-0.48, -0.53, -0.69, -0.45,  1.  ,  0.  ],\n",
       "       [-0.29, -0.28, -0.54, -0.26,  0.  ,  0.  ],\n",
       "       [-0.1 , -0.04,  0.  , -0.61,  0.  ,  1.  ],\n",
       "       [ 0.1 ,  0.13, -0.18,  0.13,  1.  ,  0.  ],\n",
       "       [ 0.29,  0.27,  0.03,  0.32,  0.  ,  1.  ],\n",
       "       [ 0.48,  0.45,  0.26,  0.51,  0.  ,  1.  ],\n",
       "       [ 0.67,  0.76,  0.5 ,  0.7 ,  0.  ,  0.  ],\n",
       "       [ 0.87,  0.88,  0.76,  0.89,  1.  ,  0.  ],\n",
       "       [ 1.06,  0.  ,  1.05,  1.08,  1.  ,  0.  ],\n",
       "       [ 1.25,  1.42,  1.35,  1.27,  0.  ,  1.  ],\n",
       "       [ 1.45,  1.55,  1.67,  1.46,  1.  ,  0.  ],\n",
       "       [ 1.64,  1.71,  2.01,  1.65,  1.  ,  0.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trans = np.around(data_trans, decimals=2)\n",
    "data_trans"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_4_complete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
